{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This first set of scripts downloads and creates AddressBase Premium.  \n",
    "\n",
    "This is a ~120GB database of all of the addresses in the UK, so some of these scripts will take quite a long time to run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prerequisites\n",
    "\n",
    "- You need a connection to a Postgres database that supports PostGIS and Full Text Search.  AWS RDS for Postgres will work.\n",
    "- The Postgres instance will need about 150GB of spare disk space\n",
    "- You will need about 100gb of spare disk space on your local machine\n",
    "- These scripts will probably take you about a day to run in total.  Most of this time is just waiting for long running processes to complete\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To perform address lookups, we use [Addressbase Premium](https://www.ordnancesurvey.co.uk/business-and-government/products/addressbase-premium.html).  This is free to the Government under the Public Sector Mapping Agreement.  You can get a login to the [PSMA portal](https://www.ordnancesurvey.co.uk/psma/) by emailing customerservices@os.uk\n",
    "\n",
    "Addressbase Premium is provided in the format of a csv file for each OS grid square.  There are a total of around 10000.  \n",
    "\n",
    "This script automatically downloads and unzips all the files.  It uses as an input \"Ordnance Survey Download Centre.htm\", which is the html page containing the download links."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use BeautifulSoup to parse this html page and pull out a list of download links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "with open(\"Ordnance Survey Download Centre.htm\") as f:\n",
    "    soup  = BeautifulSoup(f, \"lxml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many links do we expect to find?\n",
    "el = soup.find(text = \"Number of Files:\").parent.parent\n",
    "num = el.text.replace(\"Number of Files:\", \"\").strip()\n",
    "numfiles = int(num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_links = set()\n",
    "for a in soup.findAll(\"a\"):\n",
    "    if \"href\" in a.attrs:\n",
    "        if \"AB76DL\" in a[\"href\"]:  # This is a bit of trial and error, but it turned out that the download links all contain \"AB76DL\" as part of the URL\n",
    "            my_links.add(a[\"href\"])\n",
    "my_links = list(my_links)\n",
    "\n",
    "# Check we've found the right number of links\n",
    "if (len(my_links) != numfiles):\n",
    "    raise Exception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#links_done and links_failed allow us to restart from where we left off if we get an error or e.g. the internet cuts out\n",
    "links_done = set()\n",
    "links_failed = set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "from zipfile import ZipFile\n",
    "from io import BytesIO\n",
    "\n",
    "counter = 0.0\n",
    "denom = len(my_links)\n",
    "for link in my_links:\n",
    "    if link not in links_done:  \n",
    "        try:\n",
    "            counter +=1\n",
    "            if counter % 20 == 0:\n",
    "                print(counter/denom)\n",
    "            response = urlopen(link, timeout = 5)\n",
    "            zipfile = ZipFile(BytesIO(response.read()))\n",
    "\n",
    "            with zipfile as z:\n",
    "                z.extractall(\"raw/outdata/\")\n",
    "            links_done.add(link)\n",
    "        except:\n",
    "            links_failed.add(link)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, retry any links that failed with a longer timeout "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from zipfile import ZipFile\n",
    "\n",
    "links_failed2 = set()\n",
    "\n",
    "counter = 0\n",
    "denom = len(my_links)*1.0\n",
    "\n",
    "for link in links_failed:\n",
    "   \n",
    "    try:\n",
    "        counter += 1\n",
    "        print(counter)\n",
    "        response = urlopen(link, timeout = 30)\n",
    "        zipfile = ZipFile(BytesIO(response.read()))\n",
    "\n",
    "        with zipfile as z:\n",
    "            z.extractall(\"raw/outdata/\")\n",
    "        links_done.add(link)\n",
    "    except:\n",
    "        links_failed2.add(link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(links_failed2) == 0 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally  verify that the number of files downloaded is equal to the number expected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, os.path\n",
    "\n",
    "# simple version for working with CWD\n",
    "dl_files_counter = 0\n",
    "for name in os.listdir('raw/outdata/'):\n",
    "    if os.path.isfile(os.path.join('raw', 'outdata', name)):\n",
    "        if \".csv\" in name:\n",
    "            dl_files_counter += 1\n",
    "    \n",
    " \n",
    "if (len(my_links) != dl_files_counter):\n",
    "    raise Exception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
