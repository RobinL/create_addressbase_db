{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given a connection to a blank Postgres database, these scripts will create the necessary tables and then copy the data in the .csv files to the database.\n",
    "\n",
    "Note that uploading data to a remote AWS Postgres instance is a little tricky - see [here](https://stackoverflow.com/questions/46969474/using-python-to-upload-large-csv-files-to-postgres-rds-in-aws/46969475#46969475) for more info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Add folder one level up to system path so Python can 'see' the db_connections module\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "from db_connections.connections import get_conn, runsql \n",
    "from db_connections.connections import host, dbname, username"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"sql/create_abp_tables.sql\") as f:\n",
    "    sql = \" \".join(f.readlines())\n",
    "\n",
    "# THE FOLLOWING STATEMENT DROPS ALL AddressBase Premium TABLES in the database, so only use it if you really want to start from scratch\n",
    "# i.e. the following line needs to be run the first time you run this script, but be careful not to accidentally run it again, because it will delete everything in the database!\n",
    "# runsql(sql)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now need to read each table in \n",
    "copy_list = [('abp_blpu', 'ID21_BLPU_Records.csv'),\n",
    "('abp_delivery_point', 'ID28_DPA_Records.csv'),\n",
    "('abp_lpi', 'ID24_LPI_Records.csv'),\n",
    "('abp_crossref', 'ID23_XREF_Records.csv'),\n",
    "('abp_classification', 'ID32_Class_Records.csv'),\n",
    "('abp_street', 'ID11_Street_Records.csv'),\n",
    "('abp_street_descriptor', 'ID15_StreetDesc_Records.csv'),\n",
    "('abp_organisation', 'ID31_Org_Records.csv'),\n",
    "('abp_successor', 'ID30_Successor_Records.csv')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following might take about 40 minutes on a very fast connection.\n",
    "\n",
    "Note that I tried to use multithreading to make it faster, but it didn't increase the upload speed.  The maximum I was about to achive on the MoJ Digital Wifi was about 15MB/s upload."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import datetime\n",
    "import subprocess\n",
    "\n",
    "for row in copy_list:\n",
    "    command = \"\\copy {} FROM 'raw/{}' DELIMITER ',' CSV HEADER\".format(row[0], row[1])\n",
    "    psql_template = 'psql -p 5432 --host {} --username {} --dbname {} --command \"{}\"'\n",
    "    bash_command = psql_template.format(host, username, dbname, command.strip())\n",
    "    \n",
    "    print(\"---\")\n",
    "    print(datetime.datetime.now().time())\n",
    "    print(bash_command)\n",
    "    print(\"Creating table {} from {}\".format(row[0], row[1]))\n",
    "\n",
    "    process = subprocess.Popen(bash_command, stdout=subprocess.PIPE, shell=True) \n",
    " \n",
    "    output, error = process.communicate()\n",
    "    print(output)\n",
    "    print(error)\n",
    "    print(\"---\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check that the number of records in the remote tables equals the number of lines in the csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "\n",
    "def file_len(fname):\n",
    "    with open(fname) as f:\n",
    "        for i, l in enumerate(f):\n",
    "            pass\n",
    "    return i + 1\n",
    "\n",
    "\n",
    "sql = \"\"\"\n",
    "select count(*) from {}\n",
    "\"\"\"\n",
    "df_rows = []\n",
    "\n",
    "conn = get_conn()\n",
    "for row in copy_list:\n",
    "\n",
    "    table_name =  row[0]\n",
    "    df = pd.read_sql(sql.format(table_name), conn)\n",
    "    count = df.iloc[0,0]\n",
    "    line_count = file_len(\"raw/\"+row[1]) - 1 #-1 to account for header\n",
    "    df_rows.append({\"table_name\": table_name, \n",
    "                    \"count\": count,\n",
    "                    \"line_count\": line_count})\n",
    "    \n",
    "pd.DataFrame(df_rows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
